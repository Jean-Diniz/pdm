#!/bin/bash

# Script principal para executar o projeto RU-UFLA Analytics
# Suporte para execu√ß√£o local, Docker Compose e Docker Swarm
# Autor: Grupo 2

set -e

echo "üöÄ Iniciando projeto RU-UFLA Analytics..."

# Verificar se Docker est√° instalado
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker n√£o encontrado. Por favor, instale o Docker primeiro."
    exit 1
fi

# Detectar qual vers√£o do Docker Compose est√° dispon√≠vel
DOCKER_COMPOSE_CMD=""
if command -v docker-compose &> /dev/null; then
    DOCKER_COMPOSE_CMD="docker-compose"
elif docker compose version &> /dev/null; then
    DOCKER_COMPOSE_CMD="docker compose"
else
    echo "‚ùå Docker Compose n√£o encontrado. Por favor, instale o Docker Compose primeiro."
    echo "   Suporte para: 'docker-compose' (V1) ou 'docker compose' (V2)"
    exit 1
fi

echo "üîß Usando: $DOCKER_COMPOSE_CMD"

# Configurar vari√°veis de ambiente para logging
export LOG_LEVEL=${LOG_LEVEL:-INFO}
export LOG_TO_FILE=${LOG_TO_FILE:-true}
export LOG_COLORS=${LOG_COLORS:-true}

# Fun√ß√£o para mostrar ajuda
show_help() {
    echo "üìñ Uso: $0 [COMANDO]"
    echo ""
    echo "Comandos dispon√≠veis:"
    echo "  build           - Construir as imagens Docker"
    echo "  up              - Subir o cluster Spark local (padr√£o)"
    echo "  down            - Parar o cluster Spark local"
    echo "  restart         - Reiniciar o cluster Spark local"
    echo "  logs            - Mostrar logs dos containers"
    echo "  status          - Mostrar status dos containers"
    echo "  clean           - Limpar containers e volumes"
    echo "  test            - Executar testes de integra√ß√£o"
    echo "  analyze [mode]  - Executar an√°lise de dados (mode: sample|complete)"
    echo "  info            - Mostrar informa√ß√µes do sistema"
    echo ""
    echo "üê≥ Comandos Docker Swarm:"
    echo "  swarm-init      - Inicializar Docker Swarm"
    echo "  swarm-deploy    - Deploy no Docker Swarm"
    echo "  swarm-scale     - Escalar servi√ßos no Swarm"
    echo "  swarm-remove    - Remover stack do Swarm"
    echo "  swarm-logs      - Logs dos servi√ßos no Swarm"
    echo "  swarm-status    - Status dos servi√ßos no Swarm"
    echo ""
    echo "  help            - Mostrar esta ajuda"
    echo ""
    echo "üåê URLs importantes:"
    echo "  Spark Master UI:  http://localhost:8080"
    echo "  Spark App UI:     http://localhost:4040"
    echo "  Worker 1 UI:      http://localhost:8081"
    echo "  Worker 2 UI:      http://localhost:8082"
    echo ""
    echo "üîß Vari√°veis de ambiente para logging:"
    echo "  LOG_LEVEL=DEBUG|INFO|WARNING|ERROR (padr√£o: INFO)"
    echo "  LOG_TO_FILE=true|false (padr√£o: true)"
    echo "  LOG_COLORS=true|false (padr√£o: true)"
    echo ""
    echo "üí° Exemplos de uso:"
    echo "  LOG_LEVEL=DEBUG $0 up"
    echo "  $0 analyze sample      # An√°lise com dados de amostra"
    echo "  $0 analyze complete    # An√°lise completa (padr√£o)"
    echo "  $0 analyze-local sample    # An√°lise local com amostra"
    echo "  $0 analyze-local complete  # An√°lise local completa"
}

# Fun√ß√£o para construir imagens
build_images() {
    echo "üî® Construindo imagens Docker..."
    $DOCKER_COMPOSE_CMD build
    echo "‚úÖ Imagens constru√≠das com sucesso!"
}

# Fun√ß√£o para subir o cluster local
start_cluster() {
    echo "üöÄ Iniciando cluster Spark local..."
    $DOCKER_COMPOSE_CMD up -d spark-master spark-worker-1 spark-worker-2
    
    echo "‚è≥ Aguardando inicializa√ß√£o dos servi√ßos..."
    sleep 15
    
    echo "‚úÖ Cluster iniciado com sucesso!"
    echo ""
    echo "üåê Servi√ßos dispon√≠veis:"
    echo "  üî• Spark Master UI:  http://localhost:8080"
    echo "  üìà Spark App UI:     http://localhost:4040 (quando app estiver rodando)"
    echo "  üë∑ Worker 1 UI:      http://localhost:8081"
    echo "  üë∑ Worker 2 UI:      http://localhost:8082"
    echo ""
    echo "üìã Comandos √∫teis:"
    echo "  Logs:       $0 logs"
    echo "  An√°lise:    $0 analyze [sample|complete]"
    echo "  Local:      $0 analyze-local [sample|complete]"
    echo "  Parar:      $0 down"
}

# Fun√ß√£o para parar o cluster
stop_cluster() {
    echo "üõë Parando cluster Spark..."
    $DOCKER_COMPOSE_CMD down
    echo "‚úÖ Cluster parado com sucesso!"
}

# Fun√ß√£o para reiniciar o cluster
restart_cluster() {
    echo "üîÑ Reiniciando cluster Spark..."
    $DOCKER_COMPOSE_CMD restart
    echo "‚úÖ Cluster reiniciado com sucesso!"
}

# Fun√ß√£o para mostrar logs
show_logs() {
    echo "üìã Mostrando logs dos containers..."
    $DOCKER_COMPOSE_CMD logs -f
}

# Fun√ß√£o para mostrar status
show_status() {
    echo "üìä Status dos containers:"
    $DOCKER_COMPOSE_CMD ps
}

# Fun√ß√£o para limpeza
clean_all() {
    echo "üßπ Limpando recursos do projeto RU-UFLA Analytics..."
    
    # Parar e remover containers do projeto (sem remover volumes)
    $DOCKER_COMPOSE_CMD down --remove-orphans
    
    # Remover imagem espec√≠fica do projeto se existir
    if docker images | grep -q "g2-spark-master\|g2-analytics\|ru-ufla-analytics"; then
        echo "üóëÔ∏è  Removendo imagens do projeto..."
        docker images --format "table {{.Repository}}:{{.Tag}}" | grep -E "g2-|ru-ufla-analytics" | xargs -r docker rmi -f
    fi
    
    # Remover rede espec√≠fica do projeto se n√£o estiver sendo usada
    if docker network ls | grep -q "g2_spark-network"; then
        echo "üåê Removendo rede do projeto..."
        docker network rm g2_spark-network 2>/dev/null || true
    fi
    
    echo "‚úÖ Limpeza do projeto conclu√≠da!"
    echo "‚ÑπÔ∏è  Recursos de outros projetos Docker foram preservados."
}

# Fun√ß√£o para executar an√°lise
run_analysis() {
    local mode=${1:-complete}
    
    case "$mode" in
        sample)
            echo "üìä Executando an√°lise de dados do RU-UFLA (AMOSTRA)..."
            ;;
        complete)
            echo "üìä Executando an√°lise de dados do RU-UFLA (COMPLETA)..."
            ;;
        *)
            echo "‚ùå Modo inv√°lido: $mode. Use 'sample' ou 'complete'"
            return 1
            ;;
    esac
    
    # Verificar se o cluster est√° rodando
    if ! $DOCKER_COMPOSE_CMD ps | grep -q "Up"; then
        echo "‚ö†Ô∏è  Cluster n√£o est√° rodando. Iniciando..."
        start_cluster
        sleep 20
    fi
    
    # Executar an√°lise com o modo especificado
    $DOCKER_COMPOSE_CMD run --rm analytics /app/.venv/bin/python -m src.main analyze --master-url spark://spark-master:7077 --mode $mode
    echo "‚úÖ An√°lise conclu√≠da!"
}

# Fun√ß√£o para executar testes
run_tests() {
    echo "üß™ Executando testes de integra√ß√£o..."
    
    # Verificar se o cluster est√° rodando
    if ! $DOCKER_COMPOSE_CMD ps | grep -q "Up"; then
        echo "‚ö†Ô∏è  Cluster n√£o est√° rodando. Iniciando..."
        start_cluster
        sleep 20
    fi
    
    # Executar teste de conectividade
    $DOCKER_COMPOSE_CMD run --rm analytics /app/.venv/bin/python -m src.main test-spark --master-url spark://spark-master:7077
    echo "‚úÖ Testes conclu√≠dos com sucesso!"
}

# Fun√ß√£o para mostrar informa√ß√µes
show_info() {
    echo "‚ÑπÔ∏è  Mostrando informa√ß√µes do sistema..."
    
    if [ -d ".venv" ]; then
        .venv/bin/python -m src.main info
    else
        echo "‚ö†Ô∏è  Ambiente virtual n√£o encontrado. Execute 'analyze-local' primeiro."
    fi
}

# === FUN√á√ïES DOCKER SWARM ===

# Fun√ß√£o para inicializar Docker Swarm
init_swarm() {
    echo "üê≥ Inicializando Docker Swarm..."
    
    if docker info | grep -q "Swarm: active"; then
        echo "‚ÑπÔ∏è  Docker Swarm j√° est√° ativo"
    else
        docker swarm init
        echo "‚úÖ Docker Swarm inicializado!"
    fi
}

# Fun√ß√£o para deploy no Docker Swarm
deploy_swarm() {
    echo "üöÄ Fazendo deploy no Docker Swarm..."
    
    # Verificar se Swarm est√° ativo
    if ! docker info | grep -q "Swarm: active"; then
        echo "‚ö†Ô∏è  Docker Swarm n√£o est√° ativo. Inicializando..."
        init_swarm
    fi
    
    # Construir imagem
    docker build -t ru-ufla-analytics:latest .
    
    # Deploy da stack
    docker stack deploy -c docker-compose.swarm.yml ru-analytics
    
    echo "‚úÖ Deploy no Swarm conclu√≠do!"
    echo "üåê Acesse http://localhost:8080 para o Spark Master UI"
    
    # Mostrar status
    swarm_status
}

# Fun√ß√£o para escalar servi√ßos no Swarm
scale_swarm() {
    local workers=${1:-3}
    echo "üìà Escalando workers para $workers r√©plicas..."
    
    docker service scale ru-analytics_spark-worker=$workers
    echo "‚úÖ Scaling conclu√≠do!"
}

# Fun√ß√£o para remover stack do Swarm
remove_swarm() {
    echo "üóëÔ∏è  Removendo stack do Docker Swarm..."
    docker stack rm ru-analytics
    echo "‚úÖ Stack removida!"
}

# Fun√ß√£o para logs do Swarm
swarm_logs() {
    echo "üìã Logs dos servi√ßos no Swarm:"
    docker service logs -f ru-analytics_spark-master
}

# Fun√ß√£o para status do Swarm
swarm_status() {
    echo "üìä Status dos servi√ßos no Docker Swarm:"
    docker stack services ru-analytics
    echo ""
    echo "üìù Tarefas (containers) por servi√ßo:"
    docker stack ps ru-analytics
}

# Processar comando
case "${1:-up}" in
    build)
        build_images
        ;;
    up|start)
        start_cluster
        ;;
    down|stop)
        stop_cluster
        ;;
    restart)
        restart_cluster
        ;;
    logs)
        show_logs
        ;;
    status)
        show_status
        ;;
    clean)
        clean_all
        ;;
    test)
        run_tests
        ;;
    analyze)
        run_analysis $2
        ;;
    info)
        show_info
        ;;
    # Comandos Docker Swarm
    swarm-init)
        init_swarm
        ;;
    swarm-deploy)
        deploy_swarm
        ;;
    swarm-scale)
        scale_swarm $2
        ;;
    swarm-remove)
        remove_swarm
        ;;
    swarm-logs)
        swarm_logs
        ;;
    swarm-status)
        swarm_status
        ;;
    help)
        show_help
        ;;
    *)
        echo "‚ùå Comando desconhecido: $1"
        echo ""
        show_help
        exit 1
        ;;
esac 